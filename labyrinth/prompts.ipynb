{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\tA legacy text-only model optimized for chat conversations\n",
      "models/text-bison-001\tA legacy model that understands text and generates text as an output\n",
      "models/embedding-gecko-001\tObtain a distributed representation of a text.\n",
      "models/gemini-1.0-pro-latest\tThe best model for scaling across a wide range of tasks. This is the latest model.\n",
      "models/gemini-1.0-pro\tThe best model for scaling across a wide range of tasks\n",
      "models/gemini-pro\tThe best model for scaling across a wide range of tasks\n",
      "models/gemini-1.0-pro-001\tThe best model for scaling across a wide range of tasks. This is a stable model that supports tuning.\n",
      "models/gemini-1.0-pro-vision-latest\tThe best image understanding model to handle a broad range of applications\n",
      "models/gemini-pro-vision\tThe best image understanding model to handle a broad range of applications\n",
      "models/gemini-1.5-pro-latest\tMid-size multimodal model that supports up to 2 million tokens\n",
      "models/gemini-1.5-pro-001\tMid-size multimodal model that supports up to 2 million tokens\n",
      "models/gemini-1.5-pro\tMid-size multimodal model that supports up to 2 million tokens\n",
      "models/gemini-1.5-flash-latest\tFast and versatile multimodal model for scaling across diverse tasks\n",
      "models/gemini-1.5-flash-001\tFast and versatile multimodal model for scaling across diverse tasks\n",
      "models/gemini-1.5-flash\tFast and versatile multimodal model for scaling across diverse tasks\n",
      "models/embedding-001\tObtain a distributed representation of a text.\n",
      "models/text-embedding-004\tObtain a distributed representation of a text.\n",
      "models/aqa\tModel trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "print('\\n'.join([f'{m.name}\\t{m.description}' for m in genai.list_models()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google AI API key is set. GenAI configured successfully.\n",
      "Model(name='models/gemini-1.5-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro Latest',\n",
      "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "env_var = 'GOOGLE_AI_APIKEY'\n",
    "\n",
    "# model_version = 'models/gemini-1.5-flash-latest'\n",
    "model_version = 'models/gemini-1.5-pro-latest'\n",
    "\n",
    "if env_var in os.environ:\n",
    "    genai.configure(api_key=os.environ[env_var])\n",
    "    print('Google AI API key is set. GenAI configured successfully.')\n",
    "else:\n",
    "    url = 'https://aistudio.google.com/app/apikey'\n",
    "    raise Exception(f'Please get Google AI API key from {url} and put it in {env_var} environment variable (or in .env file for Jupyter)')\n",
    "\n",
    "# See more in https://github.com/google-gemini/cookbook/blob/main/quickstarts/Models.ipynb\n",
    "\n",
    "model_info = genai.get_model(model_version)\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2211\n",
      "0211\n",
      "1222 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"You can find an exit from any labyrinth if it is possible to walk through it.\n",
    "You always start from the at top left corner and try to reach the exit at the bottom right.\n",
    "If there is no way from start to exit, you just say \"the exit in unreachable\".\n",
    "The labyrinth itself is a matrix that consists on 0 and 1, where zero represents an empy cell and one represents the wall.\n",
    "You can not go through the walls!\n",
    "The only way to make a next step is to find an unoccupied cell on the left, right, above or below your current position.\n",
    "Then you can move your current position there and repeat the process recursively.\n",
    "As a result, you'll print the given labyrinth where the path is marked with 2.\n",
    "\n",
    "For example:\n",
    "\n",
    "00111\n",
    "10000\n",
    "11110\n",
    "\n",
    "Will be transformed into\n",
    "\n",
    "22111\n",
    "12222\n",
    "11112\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"Find the exit from the labyrinth if it exists. Mark the cells on the path from start to exit with number 2.\n",
    "Your starting point is in top left corner. The exit is in bottom right corner.\n",
    "\n",
    "0011\n",
    "0011\n",
    "1000\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel(model_version, system_instruction=instruction)\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221000\n",
      "220010\n",
      "121111\n",
      "121012\n",
      "012222 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Find the exit from the labyrinth if it exists. Mark the cells on the path from start to exit with number 2.\n",
    "Your starting point is in top left corner. The exit is in bottom right corner.\n",
    "You can't do diagonal moves. Only left, right, up and down. \n",
    "And you can not erase walls. It means you can replace 0 by 2 to mark your path, but you should not replace 1 by 2 (because 1 represents a wall).\n",
    "Please never overwrite the wall, which is coded with 1 in the matrix.\n",
    "If you stuck in a dead-end, feel free to return a step back and try a different direction.\n",
    "If this doesn't help, repeat recursively. If nothing helps, you can say \"the exit in unreachable\".\n",
    "Print the output labyrint matrix with the you've found path. \n",
    "The path should be continuous - it should not be any gaps in the sequence of twos which starts at top-left and goes throught the maze matrix to bottom-right.\n",
    "I don't need any code, just a result of your pass through the maze defined by the matrix below.\n",
    "\n",
    "001000\n",
    "000010\n",
    "101111\n",
    "101010\n",
    "011010\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel(model_version, system_instruction=instruction)\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
